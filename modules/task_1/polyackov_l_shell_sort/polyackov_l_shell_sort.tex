\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{amsmath}
\usepackage{graphicx}

\date{}
\title{}
\author{}

\begin{document}
\begin{titlepage}
\begin{center}
    {\bfseries МИНИСТЕРСТВО НАУКИ И ВЫСШЕГО ОБРАЗОВАНИЯ \\
        РОССИЙСКОЙ ФЕДЕРАЦИИ}\\Федеральное государственное автономное образовательное учреждение высшего образования\\
    {\bfseries «Национальный исследовательский Нижегородский государственный университет им. Н.И. Лобачевского»\\(ННГУ)\\Институт информационных технологий, математики и механики} \\
\end{center}
\vspace{8em}
\begin{center}
    ОТЧЁТ\\ по лабораторной работе \\«Применение параллельной обработки данных для сортировки Шелла»
\end{center}
\vspace{5em}
\begin{flushright}
    {\bfseries Выполнил:} студент группы\\382006-2\\Поляков Л.Д.\underline{\hspace{3cm}} \linebreak\linebreak\linebreak
    {\bfseries Проверил:} младший научный\\сотрудник\\Нестеров А.Ю. \underline{\hspace{3cm}} 
\end{flushright}
\vspace{\fill}
\begin{center}
    Нижний Новгород\\2023
\end{center}
\end{titlepage}
% Содержание
\tableofcontents
\thispagestyle{empty}
\newpage

\pagestyle{plain}
\setcounter{page}{3}
\maketitle

\section{Введение}

Сортировка — это процесс упорядочивания элементов некоторого множества по заданному критерию. Сортировка является одной из самых распространенных и важных задач программирования, так как часто необходимо обрабатывать большие объемы данных, которые легче анализировать и использовать, если они упорядочены. Существует множество алгоритмов сортировки, которые отличаются по скорости, сложности, затратам памяти и другим параметрам.

Одним из таких алгоритмов является сортировка Шелла, которая была предложена Дональдом Шеллом в 1959 году \cite{shell}. Сортировка Шелла является усовершенствованным вариантом сортировки вставками, который использует последовательность шагов для разбиения массива на подмассивы, которые затем сортируются вставками. Суть метода Шелла состоит в том, что на каждом шаге алгоритма выбирается определенное расстояние (инкремент) между сравниваемыми элементами массива. На первом шаге инкремент выбирается достаточно большим (обычно равным половине длины массива), чтобы элементы перемешались и массив стал более однородным. На последующих шагах инкремент уменьшается (обычно вдвое), пока не станет равным единице. На последнем шаге алгоритм работает как обычная сортировка вставками, но на уже почти отсортированном массиве.

Сортировка Шелла имеет ряд преимуществ перед другими методами сортировки: она проста в реализации и не требует дополнительной памяти; она работает быстрее, чем сортировка вставками, пузырьком или выбором; она не деградирует до квадратичной сложности при неудачных наборах данных; она легко адаптируется к различным типам данных и порядкам сортировки.

Однако сортировка Шелла имеет и недостатки: ее сложность зависит от выбора последовательности инкрементов, которая не имеет общего оптимального решения; ее скорость работы ниже, чем у более продвинутых методов сортировки, таких как быстрая или пирамидальная; ее параллелизация не тривиальна и требует специальных подходов.

Целью данной лабораторной работы является изучение и сравнение разных параллельных реализаций алгоритма сортировки Шелла с использованием разных технологий. Параллельная обработка данных — это способ ускорения выполнения вычислительных задач за счет распределения работы между несколькими исполнителями (процессорами, ядрами, потоками и т.д.), которые могут выполняться одновременно или независимо друг от друга. Параллельная обработка данных позволяет эффективно использовать ресурсы современных многоядерных и многопроцессорных систем, а также увеличивать масштабируемость и отказоустойчивость приложений.

Параллельная обработка данных для сортировки Шелла заключается в том, что исходный массив разбивается на несколько подмассивов, которые сортируются независимо друг от друга на разных потоках или процессорах. Затем эти подмассивы объединяются в один отсортированный массив.

\newpage
\section{Постановка задачи}
В данной работе мы рассмотрим следующие параллельные реализации алгоритма сортировки Шелла:

\begin{itemize} \item Последовательная реализация. Это базовый вариант алгоритма, который выполняется в одном потоке без использования дополнительных технологий. Эта реализация служит для сравнения производительности и корректности работы параллельных реализаций. \item Реализация с применением OpenMP. OpenMP — это стандарт для написания параллельных программ на языках C, C++ и Fortran. OpenMP позволяет создавать и управлять параллельными потоками исполнения с помощью специальных директив компилятора и библиотечных функций. OpenMP поддерживает различные модели параллелизма, такие как параллелизм циклов, секций, задач и т.д. \item Реализация с применением Intel Threading Building Blocks (TBB). TBB — это библиотека для написания параллельных программ на языке C++. TBB предоставляет высокоуровневые абстракции для создания и управления параллельными потоками исполнения, такие как параллельные алгоритмы, контейнеры, итераторы, задачи, фьючерсы и т.д. TBB также оптимизирует использование памяти и кэша для повышения производительности параллельных программ. \item Реализация с применением std::thread. std::thread — это класс из стандартной библиотеки C++, который представляет собой низкоуровневый интерфейс для работы с потоками исполнения. std::thread позволяет создавать и управлять потоками напрямую, без использования дополнительных библиотек или директив компилятора. std::thread также поддерживает различные способы синхронизации и обмена данными между потоками, такие как мьютексы, условные переменные, атомарные операции и т.д. \end{itemize}
Необходимо выполнить следующие задачи:
\begin{enumerate} \item Реализовать разные параллельные реализации алгоритма сортировки Шелла на языке программирования C++. \item Сравнить время работы разных параллельных реализаций алгоритма сортировки Шелла на разных наборах данных (случайные числа, отсортированные числа, обратно отсортированные числа и т.д.). \item Сделать выводы о преимуществах и недостатках каждой параллельной реализации и выбрать оптимальную технологию для конкретной задачи. \end{enumerate}

\newpage
\section{Описание вспомогательных функций}

\subsection{Функция get\_random\_vec} Создаёт вектор заданного размера и заполняет его случайными числами от 0 до 9999. Эта функция принимает два параметра: размер вектора и зерно для генератора случайных чисел. Зерно используется для инициализации генератора случайных чисел. Если зерно не задано, то генератор будет инициализирован нулём.

\subsection{Функция shell\_sort\_seq} Реализует алгоритм сортировки Шелла, состоящий из нескольких этапов. В данной функции на первом этапе выбирается шаг delta равный размеру входного массива делённому на 2. На втором этапе происходит сравнение и сортировка между собой значений, отстоящих друг от друга на расстоянии delta. На третьем этапе шаг delta уменьшается в два раза и происходит повторение второго этапа до тех пор, пока шаг не станет равным единице.

\subsection{Функция simple\_merge} Объединяет два входных вектора в один отсортированный вектор. В функции сначала инициализируются две целочисленные переменные first\_size и second\_size размерами входных векторов. Затем инициализируется новый вектор целых чисел под названием result\_vec с размером, равным сумме размеров входных векторов.

Затем функция входит в цикл while, который продолжается до тех пор, пока либо first\_size, либо second\_size не станут равными нулю. Внутри цикла while функция сравнивает первые элементы обоих входных векторов и добавляет меньший элемент в выходной вектор. Индекс вектора, содержащего меньший элемент, увеличивается на 1, а его размер уменьшается на 1. Индекс выходного вектора увеличивается на 1.

Если один из входных векторов был полностью обработан, то оставшиеся элементы другого входного вектора добавляются к выходному вектору.

\subsection{Функция simple\_separate} Принимает вектор целых чисел и целое число num\_of\_parts в качестве входных аргументов и возвращает вектор векторов целых чисел. Функция разделяет входной вектор на num\_of\_parts частей и возвращает каждую часть в отдельном векторе.

После обработки специфичных ситуаций, в функции вычисляется размер каждой части нового вектора как размер входного вектора, деленный на num\_of\_parts. Затем в функции используется цикл for для создания частей. Внутри цикла for функция использует метод insert для добавления элементов из входного вектора во временный вектор. Затем функция добавляет временный вектор к выходному вектору result\_vec. В конце цикла for функция добавляет оставшиеся элементы из входного вектора к последней части.

\newpage
\section{Описание применённых технологий}

\subsection{Последовательная версия}

В начале вектор данных разделяется на части с помощью функции simple\_separate.\\Каждая часть сортируется с помощью функции shell\_sort\_seq, которая реализует алгоритм Шелла (shell sort).\\Затем отсортированные части объединяются с помощью функции simple\_merge, которая реализует алгоритм простого слияния, в результате которого две отсортированные части сливаются в одну.

\subsection{OpenMP версия}

В первую очередь с помощью функции omp\_set\_num\_threads устанавливается количество потоков, которые будут использованы для параллельной обработки. В данном случае это количество равно количеству частей, на которые разделён вектор данных.

Используется цикл parallel for, который запускает функцию shell\_sort\_seq для каждого элемента вектора параллельно. Функция shell\_sort\_seq выполняет последовательную сортировку Шелла для каждого элемента.

\subsection{TBB версия}
Изначально создаётся объект класса tbb::global\_control, который устанавливает максимальное количество потоков, которые могут быть использованы для параллельной обработки. В данном случае это количество равно количеству частей, на которые разделён вектор данных.

blocked\_range - это класс шаблонов из библиотеки Intel Threading Building Blocks (TBB), который представляет диапазон значений, который может быть разделен между несколькими потоками. Он используется для разделения итераций цикла между потоками в параллельных вычислениях.

В нашем случае tbb::blocked\_range<int>(0, tmp\_res.size()) создает объект blocked\_range, который представляет диапазон значений от 0 до размера вектора tmp\_res (равному количеству частей, на которые разделён изначальный вектор данных).

Таким образом, запускается цикл parallel\_for, который разбивает вектор на блоки и запускает функцию shell\_sort\_seq для каждого блока параллельно. Функция shell\_sort\_seq выполняет последовательную сортировку Шелла для каждого блока.

\subsection{std::thread версия}
В этой версии создаётся несколько потоков. Каждый поток выполняет сортировку Шелла для своего элемента вектора. После того, как все потоки завершат свою работу, они объединяются обратно в главный поток с помощью функции join().

Кроме того, используются лямбда-функции и захват внешних переменных. Лямбда-функции - это функции без имени, которые могут быть определены и вызваны внутри другой функции. В этом коде лямбда-функция применяется для выполнения сортировки Шелла для каждой части вектора данных. Захват внешних переменных позволяет лямбда-функции использовать переменные из области видимости, в которой она была определена. В этом коде переменная i захватывается по ссылке, а переменная tmp\_res - по значению.

\newpage
\section{Результаты экспериментов}
Тестирование сортировки Шелла проводилось на различных специфических данных, помимо случайных:

\begin{itemize} \item Отсортированные данные - это данные, которые уже упорядочены по возрастанию или убыванию. На таких данных сортировка Шелла работает быстрее, чем на неотсортированных, так как требуется меньше перестановок элементов. \item Обратно сортированные данные - это данные, которые упорядочены по убыванию или возрастанию, противоположно желаемому порядку. На таких данных сортировка Шелла работает медленнее, чем на отсортированных, так как требуется больше перестановок элементов. \item Частично сортированные данные - это данные, которые содержат некоторые упорядоченные подмассивы. На таких данных сортировка Шелла работает быстрее, чем на неотсортированных, но медленнее, чем на отсортированных, так как требуется меньше перестановок элементов внутри подмассивов и больше перестановок элементов между подмассивами. \item Данные с повторяющимися элементами - это данные, которые содержат одинаковые значения. На таких данных сортировка Шелла работает стабильно и не зависит от порядка элементов. \item Все данные с одинаковыми значениями - это частный случай данных с повторяющимися элементами. На таких данных сортировка Шелла работает быстрее всего, так как не требует никаких перестановок элементов.\end{itemize} 

\newpage
\section{Вывод}
В ходе выполнения лабораторной работы были реализованы разные параллельные реализации алгоритма сортировки Шелла на языке программирования C++. Алгоритм сортировки Шелла является обобщением алгоритма сортировки вставками, который позволяет обменивать элементы, находящиеся на большом расстоянии друг от друга.

Были сравнены время работы разных параллельных реализаций алгоритма сортировки Шелла на разных наборах данных (случайные числа, отсортированные числа, обратно отсортированные числа и т.д.). Было выяснено, что время работы алгоритма сильно зависит от выбранной от степени упорядоченности данных. На отсортированных данных алгоритм работает быстрее всего, так как не требует никаких перестановок элементов. На обратно отсортированных данных алгоритм работает медленнее всего, так как требует максимального количества перестановок элементов. На случайных данных алгоритм работает со средней скоростью.

Были сделаны выводы о преимуществах и недостатках каждой параллельной реализации и выбрана оптимальная технология для конкретной задачи. Было установлено, что последовательная реализация является самой простой в реализации и отладке, но имеет самую низкую производительность. OpenMP реализация является самой удобной в использовании и позволяет легко распараллеливать циклы с помощью директив компилятора, но имеет ограничения по возможностям управления потоками. TBB реализация является самой гибкой и масштабируемой и позволяет использовать различные шаблоны параллельного программирования, но имеет большую сложность реализации. std::thread реализация является самой низкоуровневой и позволяет иметь полный контроль над потоками и синхронизацией, но имеет большую сложность реализации и больший риск ошибок.

В зависимости от целей и условий задачи можно выбрать разную технологию для параллельной реализации алгоритма сортировки Шелла. Если требуется максимальная производительность и гибкость, то можно использовать TBB или std::thread. Если требуется простота и удобство использования, то можно использовать OpenMP. Если требуется минимальное время разработки и отладки, то можно использовать последовательную реализацию.

\newpage
\begin{thebibliography}{9} \bibitem{shell} Shell D.L. A High-Speed Sorting Procedure // Communications of the ACM. — 1959. — Vol. 2, no. 7. — P. 30–32. \bibitem{shell-5} ShellSort - GeeksforGeeks. https://www.geeksforgeeks.org/shellsort/ \bibitem{shell-2} Сортировка Шелла — Википедия. https://ru.wikipedia.org/wiki/Сортировка\_Шелла \bibitem{shell-3}  Параллельная сортировка Шелла - C++ - Киберфорум. https://www.cyberforum.ru/cpp-beginners/thread2261917.html \bibitem{shell-4} Реализация сортировка Шелла — Викиучебник. https://ru.wikibooks.org/wiki/Реализации\_алгоритмов/Сортировка/Шелла.\end{thebibliography}

\newpage
\section{Приложение}
\begin{verbatim}
std::vector<int> get_random_vec(int size, unsigned int seed) {
  std::mt19937 gen;
  gen.seed(seed);

  std::vector<int> vec(size);

  for (int i = 0; i < size; i++) {
    vec[i] = gen() % 100;
  }

  return vec;
}

std::vector<int> shell_sort_seq(const std::vector<int>& vec) {
  std::vector<int> result_vec(vec);

  for (int delta = result_vec.size() / 2; delta > 0; delta /= 2) {
    for (int i = delta; i < result_vec.size(); i++) {
      int tmp = result_vec[i];

      int j;
      for (j = i; j >= delta && result_vec[j - delta] > tmp; j -= delta)
        result_vec[j] = result_vec[j - delta];

      result_vec[j] = tmp;
    }
  }
  return result_vec;
}

std::vector<int> simple_merge(const std::vector<int>& first_vec, const std::vector<int>& second_vec) {
  int i = 0, j = 0, k = 0;

  int first_size = first_vec.size();
  int second_size = second_vec.size();

  std::vector<int> result_vec(first_size + second_size);

  while (first_size != 0 && second_size != 0) {
    if (first_vec[i] < second_vec[j]) {
      result_vec[k] = first_vec[i++];
      first_size--;
    } else {
      result_vec[k] = second_vec[j++];
      second_size--;
    }
    k++;
  }

  if (first_size == 0) {
    for (int m = j; m < j + second_size; k++, m++) {
      result_vec[k] = second_vec[m];
    }
  } else if (second_size == 0) {
    for (int m = i; m < i + first_size; k++, m++) {
      result_vec[k] = first_vec[m];
    }
  }

  return result_vec;
}

std::vector<std::vector<int>> simple_separate(const std::vector<int>& vec, int num_of_parts) {
  std::vector<std::vector<int>> result_vec;
  std::vector<int> tmp;

  if (num_of_parts < 2 || vec.size() < num_of_parts) {
    result_vec.push_back(vec);
    return result_vec;
  }

  int i = 0;
  int chunk = vec.size() / num_of_parts;
  for (i = 0; i < num_of_parts - 1; i++) {
    tmp.insert(tmp.end(), vec.begin() + i * chunk, vec.begin() + i * chunk + chunk);
    result_vec.push_back(tmp);
    tmp.clear();
  }
  tmp.insert(tmp.end(), vec.begin() + i * chunk, vec.end());
  result_vec.push_back(tmp);

  return result_vec;
}

std::vector<int> shell_sort_with_simple_merge_seq(const std::vector<int>& vec, int num_of_parts) {
  std::vector<std::vector<int>> tmp_res = simple_separate(vec, num_of_parts);

  std::vector<int> res;

  for (int i = 0; i < tmp_res.size(); i++) {
    tmp_res[i] = shell_sort_seq(tmp_res[i]);
    res = simple_merge(res, tmp_res[i]);
  }

  return res;
}

std::vector<int> shell_sort_with_simple_merge_omp(const std::vector<int>& vec, int num_of_parts) {
  std::vector<std::vector<int>> tmp_res = simple_separate(vec, num_of_parts);

  std::vector<int> res;

  omp_set_num_threads(tmp_res.size());
  #pragma omp parallel for
  for (int i = 0; i < tmp_res.size(); ++i) {
    tmp_res[i] = shell_sort_seq(tmp_res[i]);
  }

  for (int i = 0; i < tmp_res.size(); i++) {
    res = simple_merge(res, tmp_res[i]);
  }

  return res;
}

std::vector<int> shell_sort_with_simple_merge_tbb(const std::vector<int>& vec, int num_of_parts) {
  std::vector<std::vector<int>> tmp_res = simple_separate(vec, num_of_parts);

  std::vector<int> res;

  tbb::global_control gc(tbb::global_control::max_allowed_parallelism, tmp_res.size());

  tbb::parallel_for(tbb::blocked_range<int>(0, tmp_res.size()), [&](const tbb::blocked_range<int>& r) {
    for (int i = r.begin(); i < r.end(); ++i) {
      tmp_res[i] = shell_sort_seq(tmp_res[i]);
    }
  });

  for (int i = 0; i < tmp_res.size(); i++) {
    res = simple_merge(res, tmp_res[i]);
  }

  return res;
}

std::vector<int> shell_sort_with_simple_merge_std(const std::vector<int>& vec, int num_of_parts) {
  std::vector<std::vector<int>> tmp_res = simple_separate(vec, num_of_parts);

  std::vector<int> res;

  std::vector<std::thread> threads;
  for (int i = 0; i < tmp_res.size(); ++i) {
    threads.emplace_back([i, &tmp_res]() {
      tmp_res[i] = shell_sort_seq(tmp_res[i]);
    });
  }
  for (auto& thread : threads) {
    thread.join();
  }

  for (int i = 0; i < tmp_res.size(); i++) {
    res = simple_merge(res, tmp_res[i]);
  }

  return res;
}

\end{verbatim}

\end{document}
